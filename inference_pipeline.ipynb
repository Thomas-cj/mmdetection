{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cb33d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.apis import init_detector, inference_detector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b52f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def detect_flashes(video_path, roi_x, roi_y, roi_width, roi_height, brightness_jump_threshold):\n",
    "    \"\"\"\n",
    "    Uses pixel intensity thresholding to estimate what frame the dive starts on.\n",
    "    Assumes the flash does not occur on the first frame of the video\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the video file.\n",
    "        roi_x (int): X-coordinate of the top-left corner of the ROI.\n",
    "        roi_y (int): Y-coordinate of the top-left corner of the ROI.\n",
    "        roi_width (int): Width of the ROI.\n",
    "        roi_height (int): Height of the ROI.\n",
    "        brightness_jump_threshold (int): Minimum increase in average pixel intensity\n",
    "            from the previous frame to trigger a flash detection.\n",
    "\n",
    "    Returns:\n",
    "        int: The frame number at which the first flash was detected, or -1 if no flash was found.\n",
    "    \"\"\"\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file: {video_path}\")\n",
    "        return\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    # extract first frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # convert to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # define roi\n",
    "    roi = gray_frame[roi_y : roi_y + roi_height, roi_x : roi_x + roi_width]\n",
    "\n",
    "    # establish inital brightness thresholds so someone doesn't just walk infront of the camera and set it off Jon\n",
    "    base_threshold = np.mean(roi)\n",
    "    previous_brightness = np.mean(roi)\n",
    "    frame_count +=1\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            # end of video \n",
    "            break  \n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # convert frame to grayscale for brightness calculation\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # create roi frame\n",
    "        roi = gray_frame[roi_y : roi_y + roi_height, roi_x : roi_x + roi_width]\n",
    "\n",
    "        current_brightness = np.mean(roi)\n",
    "            \n",
    "        # calculate the brightness change from the previous frame\n",
    "        brightness_change = current_brightness - previous_brightness\n",
    "\n",
    "        # light flash detection logic\n",
    "        if current_brightness > base_threshold and brightness_change > brightness_jump_threshold:\n",
    "        \n",
    "            cap.release()\n",
    "            return frame_count-1\n",
    "\n",
    "        # store current brightness for the next frame's comparison\n",
    "        previous_brightness = current_brightness\n",
    "    \n",
    "    cap.release()\n",
    "    print(\"No flash found\")\n",
    "\n",
    "\n",
    "def extract_frame(config, checkpoint, video_path, correction = 0, save_path=False):\n",
    "    \"\"\"\n",
    "    Finds the frame at which the x coordinate of the highest score bounding box passes 1024 pixels\n",
    "\n",
    "    Args:\n",
    "        config (str): Path to model config file. \n",
    "        checkpoint (str): Path to model checkpoint file.\n",
    "        video_path (str): Path to the video file.\n",
    "        correction (int): Number of frames skipped in video\n",
    "        save_path (str): Path to folder to save frame, defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        int: The frame number at which the x coordinate of the highest score bounding box passes 1024 pixels.\n",
    "        if save_path is True: Jpeg file of the frame saved to outputs.\n",
    "    \n",
    "    \"\"\"\n",
    "    model = init_detector(config, checkpoint, device=\"cpu\")\n",
    "    cap = mmcv.VideoReader(video_path)\n",
    "    frame_count = 0\n",
    "    for frame in cap:\n",
    "        frame_count += 1\n",
    "\n",
    "        #run model inference on frame\n",
    "        result = inference_detector(model, frame)\n",
    "\n",
    "        # if the results are not empty and the confidence score is above 0.8 extract the scores\n",
    "        if result.pred_instances and result.pred_instances.scores is not None and len(result.pred_instances.scores) > 0 and max(result.pred_instances.scores) > 0.8:\n",
    "            # index of the highest score\n",
    "            max_score_idx = np.argmax(result.pred_instances.scores)\n",
    "\n",
    "            # bounding box corresponding to the highest score\n",
    "            highest_score_bbox = result.pred_instances.bboxes[max_score_idx]\n",
    "\n",
    "            # extract leftmost x coordinate\n",
    "            x = highest_score_bbox[0]\n",
    "            # extract rightmost x coordinate\n",
    "            x2 = highest_score_bbox[2]\n",
    "\n",
    "            y = highest_score_bbox[1]\n",
    "            y2 = highest_score_bbox[3]\n",
    "\n",
    "            threshold_x = 1024\n",
    "\n",
    "            # reduced the detection window to reduce the number of false positives\n",
    "            if (x <= threshold_x) and x2 > threshold_x:\n",
    "                if save_path:\n",
    "                    # draw bbox and save frame for manual validation\n",
    "                    frame_bbox = cv2.rectangle(frame, (int(x), int(y)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
    "                    cv2.imwrite(f\"{save_path}/{correction + frame_count-1}.jpg\", frame_bbox)\n",
    "                   \n",
    "                return correction + frame_count - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "input_folder = \"test_data\"\n",
    "output_folder = \"test_results\"\n",
    "\n",
    "# number of frames to cut from each video at 5, 10 and 15m, reduces processing time and risk of FP\n",
    "correction_5 = 100\n",
    "correction_10 = 300\n",
    "correction_15 = 600\n",
    "\n",
    "# model parameters for extraction function\n",
    "checkpoint = r\"work_dirs\\faster-rcnn_r50-tnr-pre_fpn_1x_coco_full_custom_br_hue\\best_coco_Swimmer_HBB_precision_epoch_10.pth\"\n",
    "config = r\"custom_configs\\faster_rcnn\\faster-rcnn_r50-tnr-pre_fpn_1x_coco_full_custom_br_hue.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad13e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output folder\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# find all subdirectories in parent folder\n",
    "folders = []\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    for dir in dirs:\n",
    "        folders.append(os.path.join(root, dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ffd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the folders\n",
    "folder_count = 1\n",
    "for folder in folders:\n",
    "    # right now, ROI must be changed depening on the dive. \n",
    "    # This approach will only work with the light\n",
    "    # kept in a similar spot from dive to dive.\n",
    "    if folder_count == 1:\n",
    "        roi_params = {\n",
    "            \"x\": 1773,\n",
    "            \"y\": 635,\n",
    "            \"width\": 31,\n",
    "            \"height\": 29,\n",
    "            \"brightness_jump_threshold\": 30\n",
    "        }\n",
    "        # makes sure the correct param is set for correct video\n",
    "        folder_count +=1\n",
    "    else:\n",
    "        # if the dives are dives number 2-6 uses these params.\n",
    "        roi_params = {\n",
    "            \"x\": 1732,\n",
    "            \"y\": 643,\n",
    "            \"width\": 31,\n",
    "            \"height\": 29,\n",
    "            \"brightness_jump_threshold\": 30\n",
    "        }\n",
    "        folder_count +=1\n",
    "\n",
    "    # create temp folder with subfolders for each dive with the same name as the original subfolders\n",
    "    temp_out = os.path.join(output_folder, os.path.basename(os.path.normpath(folder)))\n",
    "    if not os.path.exists(temp_out):\n",
    "        os.makedirs(temp_out)\n",
    "\n",
    "    # iterate through the files\n",
    "    for filename in os.listdir(folder):\n",
    "        # find start of dive video (-3)\n",
    "        if (filename.lower().endswith(('-3.avi')) or filename.lower().endswith(('_3.avi'))):\n",
    "            # calls detect_flash function \n",
    "            start_frame = detect_flashes(\n",
    "            os.path.join(folder,filename),\n",
    "            roi_params[\"x\"],\n",
    "            roi_params[\"y\"],\n",
    "            roi_params[\"width\"],\n",
    "            roi_params[\"height\"],\n",
    "            roi_params[\"brightness_jump_threshold\"]\n",
    "        )\n",
    "    # error handling if no flash is found\n",
    "    if start_frame == None:\n",
    "        print(\"No start frame detected\")\n",
    "\n",
    "    else:\n",
    "        # 10m camera\n",
    "        for filename in os.listdir(folder):        \n",
    "            if (filename.lower().endswith(('-4.avi')) or filename.lower().endswith(('_4.avi'))):\n",
    "                output_name = \"10m.avi\"\n",
    "                \n",
    "                # write out ffmpeg command line arguments as a list\n",
    "                command = [\n",
    "                \"ffmpeg\",\n",
    "                # define input folder\n",
    "                \"-i\", os.path.join(folder,filename),\n",
    "                # filtergraph string, select= frames greater than or equal to start frame + correction, \n",
    "                # setpts= resets timestamps so first frame starts at 0\n",
    "                \"-vf\", f\"select=gte(n\\,{start_frame + correction_10}),setpts=PTS-STARTPTS\",\n",
    "                # define video codec\n",
    "                \"-c:v\", \"libx264\",\n",
    "                #define output folder\n",
    "                os.path.join(temp_out,output_name),\n",
    "                ]\n",
    "\n",
    "                # run ffmpeg command from command line, trim video of extraneous frames and save intermediate video to output folder\n",
    "                subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "\n",
    "        for filename in os.listdir(folder):\n",
    "            if (filename.lower().endswith(('-5.avi')) or filename.lower().endswith(('_5.avi'))):\n",
    "                output_name = \"5m.avi\"\n",
    "                command = [\n",
    "                \"ffmpeg\",\n",
    "                \"-i\", os.path.join(folder,filename),\n",
    "                \"-vf\", f\"select=gte(n\\,{start_frame + correction_5}),setpts=PTS-STARTPTS\",\n",
    "                \"-c:v\", \"libx264\", os.path.join(temp_out,output_name),\n",
    "                ]\n",
    "                subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "\n",
    "        for filename in os.listdir(folder):\n",
    "            if (filename.lower().endswith(('-7.avi')) or filename.lower().endswith(('_7.avi'))):\n",
    "                output_name = \"15m.avi\"\n",
    "                command = [\n",
    "                \"ffmpeg\",\n",
    "                \"-i\", os.path.join(folder,filename),\n",
    "                \"-vf\", f\"select=gte(n\\,{start_frame + correction_15}),setpts=PTS-STARTPTS\",\n",
    "                \"-c:v\", \"libx264\", os.path.join(temp_out,output_name),\n",
    "                ]\n",
    "                subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "        \n",
    "        # for each file, infer time at threshold, add missing frames and output frame with bounding box graphic\n",
    "        frame_5 = extract_frame(config, checkpoint, os.path.join(temp_out, \"5m.avi\"), correction_5, save_path=temp_out)\n",
    "\n",
    "        frame_10 = extract_frame(config, checkpoint, os.path.join(temp_out, \"10m.avi\"), correction_10, save_path=temp_out) \n",
    "\n",
    "        frame_15 = extract_frame(config, checkpoint, os.path.join(temp_out, \"15m.avi\"), correction_15, save_path=temp_out)\n",
    "        \n",
    "        # remove intermediate videos\n",
    "        os.remove(os.path.join(temp_out, \"5m.avi\"))\n",
    "        os.remove(os.path.join(temp_out, \"10m.avi\"))\n",
    "        os.remove(os.path.join(temp_out, \"15m.avi\"))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
